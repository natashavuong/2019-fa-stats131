{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iron = pd.read_csv('ironslag.csv')\n",
    "iron.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(iron.chemical, iron.magnetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn requires our predictor variables to be in a two dimensional array\n",
    "# reshape to have 1 column\n",
    "# the -1 in reshape means I don't want to figure out all the necessary dimensions\n",
    "# i want 1 column, and numpy, you figure out how many rows I need\n",
    "X = iron.chemical.values.reshape(-1,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iron.magnetic\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(iron.chemical.values, iron.magnetic.values)[0,1] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a linear model between x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear.score is the R^2 value\n",
    "# how much error is reduced from no model (variance or MSE)\n",
    "# vs having the regression model\n",
    "linear.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = np.arange(10,33).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_y_hat = linear.predict(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y)\n",
    "plt.plot(x_predict, lin_y_hat, c = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle split says 'shuffle the data' and split it into 5 equal parts\n",
    "cv = model_selection.ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cv_linear = model_selection.cross_val_score(linear, X, y, cv = cv)\n",
    "print(cv_linear)\n",
    "print(np.mean(cv_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, the above is all you need to do. But I went ahead and wrote this loop which fits the model on the training data, and makes predictions for the validation data. \n",
    "\n",
    "In each plot, the light blue dots are the training data.\n",
    "\n",
    "The green dots are the validation data.\n",
    "\n",
    "The flat green line is the mean of the validation data. That would be the prediction if no model was fit.\n",
    "\n",
    "The red line is the linear model that was trained on the training data. We hope that the red line does a better job of predicting the green points than the green line. In some cases, it does not, and we actually get a negative cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(X):\n",
    "    # create a subset of the data using the training cases in cross validation\n",
    "    tX = X[train_index, : ]\n",
    "    ty = y[train_index]\n",
    "    \n",
    "    # initialize and fite a new linear regression model\n",
    "    clin = linear_model.LinearRegression()\n",
    "    \n",
    "    # fit only on the training cases\n",
    "    clin.fit(tX, ty)\n",
    "    \n",
    "    # create a subset for the test cases\n",
    "    testX = X[test_index, :]\n",
    "    testy = y[test_index]\n",
    "    \n",
    "    # plot the training data in blue and test cases in green\n",
    "    plt.scatter(tX,ty, c = 'blue', alpha = 0.1)\n",
    "    plt.scatter(testX, testy, c = 'green')\n",
    "    \n",
    "    # plot the fitted prediction line based on the training data\n",
    "    plt.plot(x_predict, clin.predict(x_predict), c = 'red')\n",
    "    \n",
    "    # plot the mean of the test cases to show what having no model looks like\n",
    "    plt.plot(x_predict, np.repeat(np.mean(testy), len(x_predict)), c = 'lightgreen')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # the MS of having no model = variance of the test data\n",
    "    mse = np.var(testy)\n",
    "    print(mse)\n",
    "    \n",
    "    # the MS regression\n",
    "    msr = sum((testy - clin.predict(testX))**2)/len(testy)\n",
    "    print( msr )\n",
    "    \n",
    "    # the score is the proportion of reduction by having regression\n",
    "    red = (mse - msr)/mse\n",
    "    print(red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial fit - quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing polynomial features creates a polynomial based on X\n",
    "poly2 = preprocessing.PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyX = poly2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2reg = linear_model.LinearRegression(fit_intercept = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2reg.fit(polyX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2reg.score(polyX,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2_X_new = poly2.fit_transform(x_predict)\n",
    "poly2_y_hat = poly2reg.predict(poly2_X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y)\n",
    "plt.plot(x_predict, poly2_y_hat, c = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_quad = model_selection.cross_val_score(poly2reg, polyX, y, cv=cv)\n",
    "print(cv_quad)\n",
    "print(np.mean(cv_quad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polycv(degree, X, y, train_index, test_index):\n",
    "    \n",
    "    # create a subset of the data using the training cases in cross validation\n",
    "    tX = X[train_index, : ]\n",
    "    ty = y[train_index]\n",
    "    \n",
    "    # create a subset for the test cases\n",
    "    testX = X[test_index, :]\n",
    "    testy = y[test_index]\n",
    "    \n",
    "    poly = preprocessing.PolynomialFeatures(degree)\n",
    "    polytX = poly.fit_transform(tX)\n",
    "    \n",
    "    # initialize and fite a new linear regression model\n",
    "    clin = linear_model.LinearRegression()\n",
    "    \n",
    "    # fit only on the training cases\n",
    "    clin.fit(polytX, ty)\n",
    "    \n",
    "    # plot the training data in blue and test cases in green\n",
    "    plt.scatter(tX,ty, c = 'blue', alpha = 0.1)\n",
    "    plt.scatter(testX, testy, c = 'green')\n",
    "    \n",
    "    # plot the fitted prediction line based on the training data\n",
    "    plt.plot(x_predict, clin.predict(poly.fit_transform(x_predict)), c = 'red')\n",
    "    \n",
    "    # plot the mean of the test cases to show what having no model looks like\n",
    "    plt.plot(x_predict, np.repeat(np.mean(testy), len(x_predict)), c = 'lightgreen')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # the MS of having no model = variance of the test data\n",
    "    mse = np.var(testy)\n",
    "    print(mse)\n",
    "    \n",
    "    # the MS regression\n",
    "    msr = sum((testy - clin.predict(poly.fit_transform(testX)))**2)/len(testy)\n",
    "    print( msr )\n",
    "    \n",
    "    # the score is the proportion of reduction by having regression\n",
    "    red = (mse - msr)/mse\n",
    "    print(red)\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    polycv(2, X, y, train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cubic fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3 = preprocessing.PolynomialFeatures(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3X = poly3.fit_transform(X)\n",
    "poly3reg = linear_model.LinearRegression(fit_intercept = False)\n",
    "poly3reg.fit(poly3X, y)\n",
    "print(poly3reg.score(poly3X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 value of the cubic fit is better, but we will see with cross validation that it is not a better model. It is overfitting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3_X_new = poly3.fit_transform(x_predict)\n",
    "poly3_y_hat = poly3reg.predict(poly3_X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y)\n",
    "plt.plot(x_predict, poly3_y_hat, c = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cube = model_selection.cross_val_score(poly3reg, poly3X, y, cv=cv)\n",
    "print(cv_cube)\n",
    "print(np.mean(cv_cube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(X):\n",
    "    polycv(3, X, y, train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting higher order polynomials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree4\n",
    "poly4 = preprocessing.PolynomialFeatures(4)\n",
    "poly4X = poly4.fit_transform(X)\n",
    "poly4reg = linear_model.LinearRegression(fit_intercept = False)\n",
    "\n",
    "cv_4th = model_selection.cross_val_score(poly4reg, poly4X, y, cv=cv)\n",
    "print(cv_4th)\n",
    "print(np.mean(cv_4th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(X):\n",
    "    polycv(4, X, y, train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree 5\n",
    "poly5 = preprocessing.PolynomialFeatures(5)\n",
    "poly5X = poly5.fit_transform(X)\n",
    "poly5reg = linear_model.LinearRegression(fit_intercept = False)\n",
    "\n",
    "cv_5th = model_selection.cross_val_score(poly5reg, poly5X, y, cv=cv)\n",
    "print(cv_5th)\n",
    "print(np.mean(cv_5th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(X):\n",
    "    polycv(5, X, y, train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
